{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638c380a-02f3-4051-836c-4c4d6af4e7ef",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "\n",
    "Quizás una de las operaciones más básicas que podemos realizar sobre textos es contar palabras. \n",
    "Imaginemos un caso extremadamente sencillo relacionado con el aprendizaje automático. \n",
    "Pensemos en un **clasificador de positividad / negatividad**.\n",
    "\n",
    "Podríamos usar una regla simple como:\n",
    "\n",
    "> **Si \"bueno\" está en el texto, clasificamos como positivo.**\n",
    "\n",
    "Claramente, un enfoque tan sencillo va a ser propenso a muchos errores. \n",
    "A lo largo del curso iremos viendo cómo aplicarlo y mejorarlo.\n",
    "\n",
    "La operación de separar los textos en unidades básicas (o **tokens**) se llama **tokenización**.\n",
    "\n",
    "## Ejemplo de tokenización simple\n",
    "\n",
    "Supongamos que tenemos el siguiente texto:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d70b260-98cb-4642-8f79-d94d06336c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = 'Usualmente, existe una relación costo-beneficio entre las distintas técnicas.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2c5c98-e9fe-4bf1-bb7f-1c85393f366b",
   "metadata": {},
   "source": [
    "Una forma muy básica de tokenizar sería dividir el texto usando los espacios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff2b419-9c54-42d5-9ac3-da3489f01f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Usualmente,', 'existe', 'una', 'relación', 'costo-beneficio', 'entre', 'las', 'distintas', 'técnicas.']\n"
     ]
    }
   ],
   "source": [
    "tokens = doc2.split(' ')\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584062f-6018-48f4-a7f6-15934bf86067",
   "metadata": {},
   "source": [
    "Observamos que al hacer una división simple por espacios, los signos de puntuación (como las comas y puntos) permanecen unidos a las palabras, lo que puede ser un problema para algunas aplicaciones de procesamiento de lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68965319-e508-4b31-95b5-65d9c2754e8a",
   "metadata": {},
   "source": [
    "**Limitaciones de este enfoque:**\n",
    "\n",
    "1. Los signos de puntuación permanecen unidos a las palabras (\"Usualmente,\")\n",
    "2. Las palabras compuestas se dividen incorrectamente (\"costo-beneficio\" debería ser un token)\n",
    "3. No maneja contracciones (\"del\" debería ser \"de\" + \"el\")\n",
    "4. No normaliza el texto (mayúsculas, acentos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312110ff-5832-4679-a2f2-652042dd4824",
   "metadata": {},
   "source": [
    "# Variaciones en el lenguaje natural y normalización\n",
    "\n",
    "Vemos que, en castellano, el lenguaje natural (escrito) puede presentar distintas fuentes de variaciones:\n",
    "\n",
    "- Uso de **mayúsculas**\n",
    "- **Tildes** en las palabras\n",
    "- **Signos ortográficos** (comas, puntos, signos de exclamación, etc.)\n",
    "- **Errores de tipeo**\n",
    "- **Variaciones propias del lenguaje** como la conjugación verbal\n",
    "- **Artefactos de la escritura informal**, como la repetición de letras: `\"holaaa\"`\n",
    "\n",
    "## ¿Cómo abordarán esto nuestros algoritmos?\n",
    "\n",
    "Una solución es aplicar la **normalización**.\n",
    "\n",
    "> **Normalización**: en este contexto, tiene una acepción similar (aunque distinta) a la que usamos en estadística. \n",
    "> Significa transformar los textos para que las representaciones sean uniformes, minimizando variaciones que no aportan significado semántico.\n",
    "\n",
    "## Ejemplos de normalización\n",
    "\n",
    "Algunas acciones comunes de normalización son:\n",
    "\n",
    "- **Eliminar espacios innecesarios**\n",
    "- **Convertir todo a minúsculas**\n",
    "- **Quitar tildes** o acentos\n",
    "- **Eliminar signos de puntuación**\n",
    "- **Corregir errores de tipeo** (cuando sea posible)\n",
    "- **Reducir repeticiones** (por ejemplo, cambiar `\"holaaa\"` a `\"hola\"`)\n",
    "\n",
    "## Ejemplo práctico en Python\n",
    "\n",
    "Veamos cómo podríamos aplicar algunas de estas normalizaciones básicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c91ee6-2ad9-41a5-8c89-a7d65aab6242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto original: ¡Holaaa! ¿Cómo estás? Espero que muy bieeen.\n",
      "Texto normalizado: holaaa como estas espero que muy bieeen\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    # Pasar a minúsculas\n",
    "    texto = texto.lower()\n",
    "    # Quitar tildes\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Eliminar signos de puntuación\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    # Eliminar espacios extra\n",
    "    texto = ' '.join(texto.split())\n",
    "    return texto\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_original = \"¡Holaaa! ¿Cómo estás? Espero que muy bieeen.\"\n",
    "texto_normalizado = normalizar_texto(texto_original)\n",
    "\n",
    "print(\"Texto original:\", texto_original)\n",
    "print(\"Texto normalizado:\", texto_normalizado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12598d4-86ac-4ff7-bba1-df586a4af64c",
   "metadata": {},
   "source": [
    "Otra forma sería:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad3005-f0fc-4342-bf08-67f1a00e68ca",
   "metadata": {},
   "source": [
    "# Instalación y uso de Unidecode para normalización de textos\n",
    "\n",
    "Para trabajar con textos eliminando acentos (tildes) y caracteres especiales, podemos utilizar la librería **unidecode**.\n",
    "\n",
    "Primero, asegurémonos de instalarla:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e614dc3-ba42-4dac-b107-901a6482a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4909-53c6-409d-8e59-b4cfd4820c9c",
   "metadata": {},
   "source": [
    "Usamos %%capture para suprimir la salida de la instalación en el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeebb76b-768b-4b14-9130-b0723163544e",
   "metadata": {},
   "source": [
    "*Normalización rápida de un texto tokenizado*\n",
    "\n",
    "Supongamos que ya tenemos un texto que queremos procesar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbe3be9a-68c6-4475-bd2a-8887c9556703",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = 'Usualmente, existe una relación costo-beneficio entre las distintas técnicas.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d9a7c6-af8f-4024-a532-4c95a47a4653",
   "metadata": {},
   "source": [
    "Podemos tokenizar el texto rápidamente y aplicar normalización sobre cada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c68fb1e6-045a-42be-bfcb-d923e8614f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usualmente,', 'existe', 'una', 'relacion', 'costo-beneficio', 'entre', 'las', 'distintas', 'tecnicas.']\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "tokens_normalizados = [\n",
    "    unidecode.unidecode(w.lower().strip()) \n",
    "    for w in doc2.split(' ')\n",
    "]\n",
    "\n",
    "print(tokens_normalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05877c-b13f-4126-87c2-e3a4f2c7f774",
   "metadata": {},
   "source": [
    "**¿Qué estamos haciendo aquí?**\n",
    "\n",
    "  w.lower() → Pasamos cada palabra a minúsculas.\n",
    "\n",
    "  strip() → Quitamos espacios extra al inicio y final de cada palabra.\n",
    "\n",
    "  unidecode.unidecode() → Quitamos tildes o caracteres especiales, pasando todo a su versión ASCII básica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273bb9b1-7a6a-4689-a953-7cf0897675ac",
   "metadata": {},
   "source": [
    "**Otras normalizaciones más sofisticadas serían:**\n",
    "\n",
    "  - Pasar de plural al singular\n",
    "  - Convertir el genero de la plabras\n",
    "  - Conjugar los verbos en infinitivo\n",
    "\n",
    "¡Es de esperarse de que se requieran métodos más complejos!\n",
    "\n",
    "Podemos observar que con la tokenización anterior, todavía tenemos palabras con signos de puntuación y caracteres \"pegados\".\n",
    "Armar nuestro vocabulario es un paso clave \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
